{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083bb1a-5ede-4146-9e14-07951e3bae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look Ma a Spike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029a275-b07e-462d-8004-b265c91e9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mne\n",
    "from MEG_Tools import MEG\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "plt.use('Qt5Agg')\n",
    "meg = MEG('case_2225_with_spike_dipoles_sleep_2.mat')\n",
    "mne_fif = meg.get_mne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883705a-1273-413a-9e6a-f9941f86c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we find the location of a known spike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b5dd5-01b8-4b89-afdb-a0ea052a1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_spike_time = meg.spikes[0]['begin']\n",
    "known_spike_time = int(math.floor(known_spike_time))#round to second below\n",
    "known_spike_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cc42f-463b-4f15-a8c7-60e3b47792a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down_to_nearest_epoch(time, epoch_length):\n",
    "    # Rounds the time down to the nearest multiple of epoch_length\n",
    "    return int(math.floor(time / epoch_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf862e9-d095-4e99-b5f5-6b2ae91f7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make epochs\n",
    "length_of_epoch = 1\n",
    "sfreq = mne_fif.info['sfreq']\n",
    "#events = np.array([[i, 0, 1] for i in range(0, mne_fif.n_times - int(sfreq), int(sfreq))], dtype=int)\n",
    "events = np.array([[i, 0, 1] for i in range(0, mne_fif.n_times - int(length_of_epoch * sfreq), int(length_of_epoch * sfreq))], dtype=int)\n",
    "\n",
    "#epochs = mne.Epochs(mne_fif, events, event_id={'one_sec': 1}, tmin=0, tmax=1, baseline=None, preload=True)\n",
    "epochs = mne.Epochs(mne_fif, events, event_id={str(length_of_epoch)+\" sec\": 1}, tmin=0, tmax=3, baseline=None, preload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d25c0-62e4-4e37-aa7b-fed7ae654f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look....\n",
    "first_spike = epochs[round_down_to_nearest_epoch(known_spike_time,length_of_epoch)]\n",
    "\n",
    "# Plot the first epoch\n",
    "first_spike.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f305eb2-6403-4c7c-a969-f5b18252925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot - Wavelet Spike\n",
    "frequencies = np.arange(4, 70, 1)\n",
    "spike_time = round_down_to_nearest_epoch(known_spike_time,length_of_epoch)\n",
    "power = mne.time_frequency.tfr_morlet(\n",
    "    epochs[spike_time-1:spike_time+1], n_cycles=2, return_itc=False, freqs=frequencies, decim=3\n",
    ")\n",
    "power.plot([\"MEG0242\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d932a-2fad-4e60-8b06-6fcf5184af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot - Wavelet Non-Spike\n",
    "frequencies = np.arange(4, 70, 1)\n",
    "power = mne.time_frequency.tfr_morlet(\n",
    "    epochs[length_of_epoch*3:length_of_epoch*4], n_cycles=2, return_itc=False, freqs=frequencies, decim=3\n",
    ")\n",
    "power.plot([\"MEG0242\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9412a-b4ec-4327-b599-cf45a0a8c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "epochs[spike_time-1:spike_time+1].plot_image(picks=[\"MEG0242\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641b080-b5fc-4b53-80f5-74b012ccd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spiked_lists(epochs_,meg_):\n",
    "    epochlength = round_down_to_nearest_epoch(len(epochs_), length_of_epoch)\n",
    "    # Creating spiked_list from meg.spikes\n",
    "    #spiked_list_ = []\n",
    "    #for n in range(len(meg_.spikes)):\n",
    "    #    begin = meg_.spikes[n]['begin']\n",
    "    #    if (begin <= epochlength):\n",
    "    #        spiked_list_.append(int(math.floor(begin)))\n",
    "    spiked_list_ = []\n",
    "    for spike in meg_.spikes:\n",
    "        begin = spike['begin']\n",
    "        rounded_begin = round_down_to_nearest_epoch(begin, length_of_epoch)\n",
    "        spiked_list_.append(rounded_begin)\n",
    "    \n",
    "    # Remove duplicates and sort spiked_list\n",
    "    spiked_list_ = sorted(list(set(spiked_list_)))\n",
    "    \n",
    "    # Creating unspiked_list\n",
    "    unspiked_list_ = [i for i in range(epochlength) if i not in spiked_list_]\n",
    "    \n",
    "    spiked_epochs_ = epochs_[spiked_list_]\n",
    "    unspiked_epochs_ = epochs_[unspiked_list_]\n",
    "    return (spiked_list_,unspiked_list_,spiked_epochs_,unspiked_epochs_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2d976-f208-4aa2-bf88-9b0e684c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spiked_list,unspiked_list,spiked_epochs, unspiked_epochs) = get_spiked_lists(epochs,meg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff8efb-761c-4334-85a5-15480be02135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "spiked_evoked = spiked_epochs.average()\n",
    "unspiked_evoked = unspiked_epochs.average()\n",
    "\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    dict(spiked=spiked_evoked, unspiked=unspiked_evoked),\n",
    "    legend=\"upper left\",\n",
    "    show_sensors=\"upper right\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b87347-84eb-4e23-972c-e91a0841f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "evoked_diff = mne.combine_evoked([spiked_evoked, unspiked_evoked], weights=[1, -1])\n",
    "evoked_diff.pick(picks=\"mag\").plot_topo(color=\"r\", legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709a6a0-a373-4cdc-bdd8-1a628a3a55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot - Hmmmm\n",
    "spiked_evoked.plot_joint(picks=\"mag\")\n",
    "spiked_evoked.plot_topomap(times=[0.0, 0.08, 0.1, 0.12, 0.2], ch_type=\"mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ce863-354c-4a0c-86ae-c8331ea8ab2d",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827cf7b-ddc5-4870-8465-805b6697645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import pywt\n",
    "from scipy.stats import skew, kurtosis  # Importing skew and kurtosis\n",
    "\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        toc = time.perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        print(f\"Elapsed time: {elapsed_time:0.4f} seconds\")\n",
    "        return value\n",
    "    return wrapper_timer\n",
    "\n",
    "def get_labels(spiked_list_,unspiked_list_):\n",
    "    # Total number of epochs (assuming the highest value from either list is the last epoch)\n",
    "    total_epochs = max(spiked_list_ + unspiked_list_) + 1  # +1 because lists are 0-indexed\n",
    "    \n",
    "    # Initialize a list with zeros (assuming all epochs are initially unspiked)\n",
    "    labels_ = [0] * total_epochs\n",
    "    \n",
    "    # Set the spiked epochs to 1\n",
    "    for index in spiked_list_:\n",
    "        labels_[index] = 1\n",
    "    return labels_\n",
    "\n",
    "@timer\n",
    "def get_features(epochs_):\n",
    "    \n",
    "    features_ = []\n",
    "    #mne.set_log_level('WARNING')\n",
    "    \n",
    "    for n in range(len(epochs_)):\n",
    "        # Progress indicator\n",
    "        perc = np.round(100 * n / len(epochs_), 1)\n",
    "        print(f\"Progress: {perc}%\", end='\\r', flush=True)\n",
    "\n",
    "        data = epochs_[n].get_data(copy=False)[0]\n",
    "\n",
    "        # Apply Discrete Wavelet Transform\n",
    "        coeffs = pywt.wavedec(data, wavelet='db4', level=4)  # Example: 4-level decomposition\n",
    "\n",
    "        epoch_features = []\n",
    "        # Calculate features for each coefficient level\n",
    "        for coeff in coeffs:\n",
    "            # Here, ensure that each feature extracted is a single value and not an array\n",
    "            energy = np.sum(coeff**2)\n",
    "            mean_coeff = np.mean(coeff)\n",
    "            var_coeff = np.var(coeff)\n",
    "            skew_coeff = skew(coeff)\n",
    "            kurt_coeff = kurtosis(coeff)\n",
    "\n",
    "            # Append each feature to epoch_features\n",
    "            epoch_features.extend([energy, mean_coeff, var_coeff, skew_coeff, kurt_coeff])\n",
    "\n",
    "        # Append the feature set for this epoch to features_\n",
    "        features_.append(epoch_features)\n",
    "    return features_\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57523429-c9a4-48b3-a20a-487ea639fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = get_features(epochs)\n",
    "labels = get_labels(spiked_list,unspiked_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1dc1f4-1c44-4015-b261-083a45598459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_mixed_list(mixed_list):\n",
    "    flattened_list = []\n",
    "    for item in mixed_list:\n",
    "        if isinstance(item, list) or isinstance(item, np.ndarray):\n",
    "            # If the item is a list or numpy array, extend the flattened list with the flattened item\n",
    "            flattened_list.extend(flatten_mixed_list(item))\n",
    "        else:\n",
    "            # If the item is not a list, just append it to the flattened list\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list\n",
    "\n",
    "\n",
    "for n in range(len(features)):\n",
    "    features[n] = flatten_mixed_list(features[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191dbdb-6936-400a-ba74-407c8c3435ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "spiked_labels = labels.copy()\n",
    "n_clusters = 6 \n",
    "# Apply K-means Clustering with clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init = 'auto').fit(features)\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Reduce the feature dimensions to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_features = pca.fit_transform(features)\n",
    "\n",
    "# Scatter plot of the seven clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in range(n_clusters):\n",
    "    mask = (cluster_labels == cluster)\n",
    "    plt.scatter(reduced_features[mask, 0], reduced_features[mask, 1], label=f'Cluster {cluster}')\n",
    "\n",
    "# Optionally, plot the centroids\n",
    "centroids = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, color='k', label='Centroids')\n",
    "\n",
    "plt.xlabel('PCA Feature 1')\n",
    "plt.ylabel('PCA Feature 2')\n",
    "plt.title(f'2D Visualization of {n_clusters} Clusters')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Counting spiked instances in each cluster\n",
    "for cluster in range(n_clusters):\n",
    "    # Counting spiked instances in the current cluster\n",
    "    this_cluster_spiked_count = sum(spiked_labels[n] for n in range(len(spiked_labels)) if cluster_labels[n] == cluster)\n",
    "    print(f\"Cluster {cluster} contains {this_cluster_spiked_count} spiked instances\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b82c4-a2bd-401d-9035-b0662faae4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
